# nlp_colabs

En este repositorio es posible encontrar dos de los notebooks principales usados para el desarrollo del proyecto de mejora del modelo Distilbert.

En concreto, se aplicó la metodología de capa alternada para poder realizar la investigación y poder producir las mejoras.

Se logró generar varios modelos que poseen rendimientos mejores a este último al ser testeados en el dataset de Superglue, en concreto el modelo de capas superiores obtiene un puntaje general ligeramente mayor, pero con un rendimiento mucho más destacable que el original en la tarea Wsc.

Los modelos generados pueden ser descargados desde ´´´https://huggingface.co/manarea´´´ y pueden ser ejecutados en el ambiente de Jiant modificado desde este mismo repositorio.
